# ğŸš€ spring-batch-kafka

Repository d'exemple d'application Spring Batch avec intÃ©gration:
- Kafka
- PostgreSQL
- GCP Storage

# ğŸ‘¨â€ğŸ« Description du projet
Ce repo prÃ©sente plusieurs modules :
> - **application**
>   - Application dÃ©ployÃ©e, elle contient la classe main
>   - DÃ©finie le job d'exÃ©cution et de ses steps
> - **commande-domain**
>   - Contient uniquement les interfaces et le code propre au domain : 
>     - Comment le filtrage est effectuÃ©.
>     - Comment la transformation est effectuÃ©e.
>     - Les objets du domain
> - **gcp-storage-writer** :
>   - Adapter implÃ©mentant un ItemWriter permettant l'Ã©criture des fichiers
>   - Fourni une configuration des propriÃ©tÃ©s via le fichier application.yaml
>   - Composant gÃ©nÃ©rique n'ayant pas besoin du module commande-domain
> - **kafka-reader** :
>   - Adapter implÃ©mentant un KafkaItemReader permettant la consommation d'un topic
>   - Fourni une configuration des propriÃ©tÃ©s via le fichier application.yaml
>   - Composant gÃ©nÃ©rique n'ayant pas besoin du module commande-domain
> - **postgres-reader** :
>   - Adapter implÃ©mentant un JdbcPagingItemReader permettant la rÃ©cupÃ©ration d'Ã©lÃ©ment dans une base de donnÃ©e
>   - Fourni une configuration des propriÃ©tÃ©s via le fichier application.yaml
>   - Composant gÃ©nÃ©rique n'ayant pas besoin du module commande-domain
> - **postgres-writer** :
>   - Adapter implÃ©mentant un JdbcBatchItemWriter permettant d'effectuer du batch insert en base de donnÃ©es
>   - Composant gÃ©nÃ©rique n'ayant pas besoin du module commande-domain

# ğŸï¸ Utilisation de l'application

Monter l'infra en local:
```shell
docker compose up
```

Ensuite, il sera nÃ©cessaire de produire des messages sur le topic appro-event. Pour cela, deux solutions possibles :
- Utiliser le plugin [Kafka](https://www.jetbrains.com/help/idea/big-data-tools-kafka.html) d'Intellij et se baser sur l'exemple [exemple-message.json](exemple-message.json)
- Utiliser la requÃªte HTTP prÃ©sente dans [request.http](request.http) qui s'appuie sur un conteneur [REST-Proxy](https://docs.confluent.io/platform/current/kafka-rest/api.html)

Vous pourrez alors dÃ©marrer l'application qui se chargera d'effectuer le traitement dÃ©cris ci-dessous ğŸ‘‡

# ğŸ“Š FLow Chart
```mermaid
flowchart TD
    B@{shape: procs, label: "Step Filtrage"} --> |RÃ©cupÃ©ration des commandes| A(Kafka)
    B --> |Enregistrement des fournitures| C[(PostgreSQL)]
    D@{shape: procs, label: "Step Transformation"} --> |RÃ©cupÃ©ration des fournitures| C
    D --> |Ã‰criture des fichiers| EA@{ shape: lin-cyl, label: "GCP Storage"}
```

## ğŸ¯ PrÃ©cisions
ğŸ—ƒï¸ L'Ã©criture et la mise Ã  jour des entrÃ©es en base s'effectue en mode Batch via l'utilisation de la spÃ©cialisation JdbcBatchItemWriter.<br/>
ğŸ“‘ La lecture des entrÃ©es repose sur l'utilisation d'un JdbcPagingItemReader.<br/>
âŒ Les messages Kafka ne sont pas acquittÃ©s tant qu'ils n'ont pas Ã©tÃ© enregistrÃ©s dans la base de donnÃ©es.<br/>
ğŸ‘ Une configuration permet de spÃ©cifier l'offset d'une ou des partitions Ã  partir duquel commencer la consommation :
```yaml
batch-kafka:
  reader:
    # Partitions Ã  consommer
    partitions:
      - 0
      - 1
      - 2
    # Nom du processus utilisÃ© pour le suivi dans les tables Spring Batch
    process-name: retrieveCommande
    # DurÃ©e maximum d'attente aprÃ¨s la consommation du dernier message avec de passer au step de transformation
    poll-timeout: 5
    # Topic de lecture
    topic: appro-event
    # Facultatif, permet de spÃ©cifier les offsets des partitions consommÃ©es (rejeu)
    partition-offset:
      - offset: 0
        partition: 0
      - offset: 0
        partition: 1
      - offset: 0
        partition: 2
```
ğŸ“˜ La description des propriÃ©tÃ©s custom est expliquÃ©e dans le fichier [CONFIGURATION.md](CONFIGURATION.md)

# ğŸ§‘â€ğŸ« Bonnes pratiques

- âŒ Ne pas gÃ©rer manuellement les transactions
- âœ… Utiliser les spÃ©cialisations de Spring concernant les interfaces ItemReader / ItemWriter / ItemProcessor
- âœ… Utiliser un dÃ©coupage par lot (Chunk) et ne pas passer des listes entre ItemReader / ItemProcessor / ItemWriter
- âŒ Ne pas utiliser les listeners pour effectuer un traitement
- âœ… Utiliser les CompositeItemReader / CompositeItemProcessor / CompositeItemWriter pour chaÃ®ner plusieurs ItemReader / ItemProcessor / ItemWriter
- âœ… PrÃ©fÃ©rer l'implÃ©mentation de plusieurs ItemProcessor effectuant des petites tÃ¢ches qu'un seul qui ferait plusieurs opÃ©rations sensibles
  - ğŸ‘‰ Pour la gestion des transactions et des retry notamment